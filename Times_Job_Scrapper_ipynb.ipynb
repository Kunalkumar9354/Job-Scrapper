{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F__7oT2h3jGM"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60645875"
      },
      "outputs": [],
      "source": [
        "scrapejobs = requests.get(\"https://www.timesjobs.com/candidate/job-search.html?searchType=personalizedSearch&from=submit&txtKeywords=Power+bi&txtLocation=NEW+DELHI\")\n",
        "soup = BeautifulSoup(scrapejobs.content,\"html.parser\")\n",
        "Jobs = soup.find_all(\"li\",class_=\"clearfix job-bx wht-shd-bx\")\n",
        "for Job in Jobs:\n",
        "    JobTitle = Job.find(\"h2\").a.text\n",
        "    CompanyName = Job.find(\"h3\",class_ = \"joblist-comp-name\").text.strip()\n",
        "    KeySkills = Job.find(\"span\", class_ = \"srp-skills\").text.replace(\" \",\"\")\n",
        "    print(f\"Job Title:{JobTitle}\")\n",
        "    print(f\"Company Name :{CompanyName}\")\n",
        "    print(f\"Key Skills:{KeySkills}\")\n",
        "    print(\"***********\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8419da51"
      },
      "outputs": [],
      "source": [
        "# Fetching the Recent jobs\n",
        "scrapejobs = requests.get(\"https://www.timesjobs.com/candidate/job-search.html?searchType=personalizedSearch&from=submit&txtKeywords=Power+bi&txtLocation=NEW+DELHI\")\n",
        "soup = BeautifulSoup(scrapejobs.content,\"html.parser\")\n",
        "Jobs = soup.find_all(\"li\",class_=\"clearfix job-bx wht-shd-bx\")\n",
        "for Job in Jobs:\n",
        "    Time = Job.find(\"span\",class_= \"sim-posted\").span.text\n",
        "    if \"few\" in Time:\n",
        "        JobTitle = Job.find(\"h2\").a.text\n",
        "        CompanyName = Job.find(\"h3\",class_ = \"joblist-comp-name\").text.strip()\n",
        "        KeySkills = Job.find(\"span\", class_ = \"srp-skills\").text.replace(\" \",\"\")\n",
        "        print(f\"Job Title:{JobTitle}\")\n",
        "        print(f\"Company Name :{CompanyName}\")\n",
        "        print(f\"Key Skills:{KeySkills}\")\n",
        "        print(\"***********\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding Fucntionality Search Functionality\n",
        "scrapejobs = requests.get(\"https://www.timesjobs.com/candidate/job-search.html?searchType=personalizedSearch&from=submit&txtKeywords=Power+bi&txtLocation=NEW+DELHI\")\n",
        "soup = BeautifulSoup(scrapejobs.content,\"html.parser\")\n",
        "print(\"Input the skills that you are unfamiliar with\")\n",
        "unfamiliar_skills = input(\"Enter the Skill : \")\n",
        "print(\"Loding Jobs according to your Skills\")\n",
        "print(\"********************\")\n",
        "Jobs = soup.find_all(\"li\",class_=\"clearfix job-bx wht-shd-bx\")\n",
        "for Job in Jobs:\n",
        "    Time = Job.find(\"span\",class_= \"sim-posted\").span.text\n",
        "    if \"few\" in Time:\n",
        "        JobTitle = Job.find(\"h2\").a.text\n",
        "        CompanyName = Job.find(\"h3\",class_ = \"joblist-comp-name\").text.strip()\n",
        "        KeySkills = Job.find(\"span\", class_ = \"srp-skills\").text.replace(\" \",\"\")\n",
        "        if unfamiliar_skills not in KeySkills:\n",
        "            print(f\"Job Title:{JobTitle}\")\n",
        "            print(f\"Company Name :{CompanyName}\")\n",
        "            print(f\"Key Skills:{KeySkills}\")\n",
        "            print(\"***********\")"
      ],
      "metadata": {
        "id": "cvxSYqy04KzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def ScrapeJobs():\n",
        "    scrapejobs = requests.get(\"https://www.timesjobs.com/candidate/job-search.html?searchType=personalizedSearch&from=submit&txtKeywords=Power+bi&txtLocation=NEW+DELHI\")\n",
        "    soup = BeautifulSoup(scrapejobs.content,\"html.parser\")\n",
        "    print(\"Input the skills that you are unfamiliar with\")\n",
        "    unfamiliar_skills = input(\"Enter the Skill : \")\n",
        "    print(\"Loding Jobs according to your Skills\")\n",
        "    print(\"********************\")\n",
        "    Jobs = soup.find_all(\"li\",class_=\"clearfix job-bx wht-shd-bx\")\n",
        "    for Job in Jobs:\n",
        "        Time = Job.find(\"span\",class_= \"sim-posted\").span.text\n",
        "        if \"few\" in Time:\n",
        "            JobTitle = Job.find(\"h2\").a.text\n",
        "            CompanyName = Job.find(\"h3\",class_ = \"joblist-comp-name\").text.strip()\n",
        "            KeySkills = Job.find(\"span\", class_ = \"srp-skills\").text.replace(\" \",\"\")\n",
        "            if unfamiliar_skills not in KeySkills:\n",
        "                print(f\"Job Title:{JobTitle}\")\n",
        "                print(f\"Company Name :{CompanyName}\")\n",
        "                print(f\"Key Skills:{KeySkills}\")\n",
        "                print(\"***********\")\n",
        "if __name__ == \"__main__\":\n",
        "    while True:\n",
        "        ScrapeJobs()\n",
        "        Waiting_Time = 1\n",
        "        print(f\"Waiting For 6 seconds\")\n",
        "        time.sleep(6*Waiting_Time)"
      ],
      "metadata": {
        "id": "OJLJ05nM4K-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding Jobs Folder By Creating Path using file system in Python using Path library\n",
        "import time\n",
        "from pathlib import Path\n",
        "def ScrapeJobs():\n",
        "    scrapejobs = requests.get(\"https://www.timesjobs.com/candidate/job-search.html?searchType=personalizedSearch&from=submit&txtKeywords=Power+bi&txtLocation=NEW+DELHI\")\n",
        "    soup = BeautifulSoup(scrapejobs.content,\"html.parser\")\n",
        "    print(\"Input the skills that you are unfamiliar with\")\n",
        "    unfamiliar_skills = input(\"Enter the Skill : \")\n",
        "    print(\"Loding Jobs according to your Skills\")\n",
        "    print(\"********************\")\n",
        "    Jobs = soup.find_all(\"li\",class_=\"clearfix job-bx wht-shd-bx\")\n",
        "    posts_directory = Path(\"posts\")\n",
        "    posts_directory.mkdir(parents=True, exist_ok=True)\n",
        "    for index,Job in enumerate(Jobs):\n",
        "        Time = Job.find(\"span\",class_= \"sim-posted\").span.text\n",
        "        if \"few\" in Time:\n",
        "            JobTitle = Job.find(\"h2\").a.text\n",
        "            CompanyName = Job.find(\"h3\",class_ = \"joblist-comp-name\").text.strip()\n",
        "            KeySkills = Job.find(\"span\", class_ = \"srp-skills\").text.replace(\" \",\"\")\n",
        "            if unfamiliar_skills not in KeySkills:\n",
        "                with open(posts_directory / f\"job{index + 1}.txt\", \"w\") as f:\n",
        "                    f.write(f\"Job Title:{JobTitle}\")\n",
        "                    f.write(f\"Company Name :{CompanyName}\")\n",
        "                    f.write(f\"Key Skills:{KeySkills}\")\n",
        "                    f.write(\"***********\")\n",
        "if __name__ == \"__main__\":\n",
        "    while True:\n",
        "        ScrapeJobs()\n",
        "        Waiting_Time = 1\n",
        "        print(f\"Waiting For 6 seconds\")\n",
        "        time.sleep(6*Waiting_Time)\n",
        ""
      ],
      "metadata": {
        "id": "ubON16hb4LB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding a functionaity so that the user can put more then one unfamilair skills\n",
        "import time\n",
        "from pathlib import Path\n",
        "def ScrapeJobs():\n",
        "    scrapejobs = requests.get(\"https://www.timesjobs.com/candidate/job-search.html?searchType=personalizedSearch&from=submit&txtKeywords=Power+bi&txtLocation=NEW+DELHI\")\n",
        "    soup = BeautifulSoup(scrapejobs.content,\"html.parser\")\n",
        "    print(\"Input the skills that you are unfamiliar with\")\n",
        "    Input_unfamiliar_skills = input(\"Enter the skills\")\n",
        "    unfamiliar_skills = []\n",
        "    skills_list = Input_unfamiliar_skills.strip(\",\")\n",
        "    for skills in skills_list:\n",
        "        stripped_skills =skills.strip()\n",
        "        unfamiliar_skills.append(stripped_skills)\n",
        "    print(\"Loding Jobs according to your Skills\")\n",
        "    print(\"********************\")\n",
        "    Jobs = soup.find_all(\"li\",class_=\"clearfix job-bx wht-shd-bx\")\n",
        "    posts_directory = Path(\"posts\")\n",
        "    posts_directory.mkdir(parents=True, exist_ok=True)\n",
        "    for index,Job in enumerate(Jobs):\n",
        "        Time = Job.find(\"span\",class_= \"sim-posted\").span.text\n",
        "        if \"few\" in Time:\n",
        "            JobTitle = Job.find(\"h2\").a.text\n",
        "            CompanyName = Job.find(\"h3\",class_ = \"joblist-comp-name\").text.strip()\n",
        "            KeySkills = Job.find(\"span\", class_ = \"srp-skills\").text.replace(\" \",\"\")\n",
        "            if unfamiliar_skills not in KeySkills:\n",
        "                with open(posts_directory / f\"job{index + 1}.txt\", \"w\") as f:\n",
        "                    f.write(f\"Job Title:{JobTitle}\")\n",
        "                    f.write(f\"Company Name :{CompanyName}\")\n",
        "                    f.write(f\"Key Skills:{KeySkills}\")\n",
        "                    f.write(\"***********\")\n",
        "if __name__ == \"__main__\":\n",
        "    while True:\n",
        "        ScrapeJobs()\n",
        "        Waiting_Time = 1\n",
        "        print(f\"Waiting For 6 seconds\")\n",
        "        time.sleep(6*Waiting_Time)"
      ],
      "metadata": {
        "id": "SdHkcKAJ4LE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NgFQLngr4LHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d2GZAUDT4LKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dFtro6T04LNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FxwH-o_y4LQr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}